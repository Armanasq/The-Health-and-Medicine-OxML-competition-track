{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "439cdfc5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-21T09:29:16.247519Z",
     "iopub.status.busy": "2023-06-21T09:29:16.246437Z",
     "iopub.status.idle": "2023-06-21T09:29:16.264459Z",
     "shell.execute_reply": "2023-06-21T09:29:16.263515Z"
    },
    "papermill": {
     "duration": 0.025908,
     "end_time": "2023-06-21T09:29:16.266609",
     "exception": false,
     "start_time": "2023-06-21T09:29:16.240701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        os.path.join(dirname, filename)\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5649fd3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T09:29:16.275932Z",
     "iopub.status.busy": "2023-06-21T09:29:16.274422Z",
     "iopub.status.idle": "2023-06-21T09:29:21.035845Z",
     "shell.execute_reply": "2023-06-21T09:29:21.034863Z"
    },
    "papermill": {
     "duration": 4.768275,
     "end_time": "2023-06-21T09:29:21.038439",
     "exception": false,
     "start_time": "2023-06-21T09:29:16.270164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import *\n",
    "from torchvision import transforms\n",
    "from torchvision.models import *\n",
    "\n",
    "import random\n",
    "\n",
    "def set_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Call the function to set the seeds\n",
    "set_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20e31088",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T09:29:21.046686Z",
     "iopub.status.busy": "2023-06-21T09:29:21.046150Z",
     "iopub.status.idle": "2023-06-21T09:30:29.688202Z",
     "shell.execute_reply": "2023-06-21T09:30:29.687134Z"
    },
    "papermill": {
     "duration": 68.649332,
     "end_time": "2023-06-21T09:30:29.691002",
     "exception": false,
     "start_time": "2023-06-21T09:29:21.041670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1/8\n",
      "Training on fold 2/8\n",
      "Training on fold 3/8\n",
      "Training on fold 4/8\n",
      "Training on fold 5/8\n",
      "Training on fold 6/8\n",
      "Training on fold 7/8\n",
      "Training on fold 8/8\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_dir, labels_file, transform=None, filenames=None, labels=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.labels_df = pd.read_csv(labels_file)\n",
    "        self.transform = transform\n",
    "\n",
    "        # Use provided filenames and labels if available\n",
    "        if filenames is not None and labels is not None:\n",
    "            self.filenames = filenames\n",
    "            self.labels = labels\n",
    "            self.use_additional_data = True\n",
    "        else:\n",
    "            self.filenames = self.labels_df['id'].astype(str).values\n",
    "            self.labels = self.labels_df['malignant'].values + 1\n",
    "            self.use_additional_data = False\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.use_additional_data:\n",
    "            img_path = os.path.join(self.image_dir, 'img_' + str(self.filenames[idx]) + '.png')\n",
    "        else:\n",
    "            img_path = os.path.join(self.image_dir, 'img_' + str(self.labels_df.iloc[idx]['id']) + '.png')\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Set the directory paths\n",
    "image_dir = '/kaggle/input/oxml-carinoma-classification'\n",
    "labels_file = '/kaggle/input/oxml-carinoma-classification/labels.csv'\n",
    "\n",
    "\n",
    "# Load the labeled dataset\n",
    "labeled_data = pd.read_csv(labels_file)\n",
    "\n",
    "# Get the labeled image filenames and their corresponding labels\n",
    "labeled_filenames = labeled_data['id'].astype(str).values\n",
    "labels = labeled_data['malignant'].values + 1\n",
    "\n",
    "# Find the maximum size\n",
    "max_width = 0\n",
    "max_height = 0\n",
    "\n",
    "for file_name in labeled_filenames:\n",
    "    file_path = os.path.join(image_dir, \"img_\" + file_name + '.png')\n",
    "    image = Image.open(file_path)\n",
    "    width, height = image.size\n",
    "    max_width = max(max_width, width)\n",
    "    max_height = max(max_height, height)\n",
    "\n",
    "\n",
    "# Define the main data transform\n",
    "main_transform = transforms.Compose([\n",
    "    transforms.Resize((max_height, max_width)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Create the main dataset\n",
    "dataset = CustomDataset(image_dir, labels_file, transform=main_transform)\n",
    "\n",
    "# Define data augmentation transforms\n",
    "augmentation_transform = transforms.Compose([\n",
    "    transforms.Resize((max_height, max_width)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset_augmented = CustomDataset(image_dir, labels_file, transform=augmentation_transform)\n",
    "\n",
    "# Define data augmentation transforms 2\n",
    "augmentation_transform_2 = transforms.Compose([\n",
    "    transforms.Resize((max_height, max_width)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.RandomResizedCrop((max_height, max_width), scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.1, p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset_augmented_2 = CustomDataset(image_dir, labels_file, transform=augmentation_transform_2)\n",
    "\n",
    "\n",
    "stacked_dataset = ConcatDataset([dataset, dataset_augmented])\n",
    "stacked_labels = np.concatenate([labels, labels])\n",
    "\n",
    "\n",
    "# Define the number of folds for k-fold cross-validation\n",
    "k_folds = 8\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "fold_scores = []\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(skf.split(stacked_dataset, stacked_labels)):\n",
    "    print(f\"Training on fold {fold + 1}/{k_folds}\")\n",
    "\n",
    "    # Split the dataset into train and validation sets for the current fold\n",
    "    train_data = [stacked_dataset[idx] for idx in train_index]\n",
    "    val_data = [stacked_dataset[idx] for idx in val_index]\n",
    "\n",
    "\n",
    "    # Convert labels to numpy array for indexing\n",
    "    stacked_labels = np.array(stacked_labels)\n",
    "\n",
    "    # Calculate class weights\n",
    "    class_weights = 1.0 / torch.tensor(np.bincount(stacked_labels[train_index]))\n",
    "    train_class_weights = class_weights[stacked_labels[train_index]]\n",
    "\n",
    "    # Create the weighted sampler\n",
    "    sampler = WeightedRandomSampler(train_class_weights, len(train_data), replacement=True)\n",
    "\n",
    "    # Create the data loaders with weighted sampling\n",
    "    batch_size = 8\n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size, sampler=sampler)\n",
    "    val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ec4d1de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T09:30:29.700953Z",
     "iopub.status.busy": "2023-06-21T09:30:29.700604Z",
     "iopub.status.idle": "2023-06-21T09:31:17.901786Z",
     "shell.execute_reply": "2023-06-21T09:31:17.900140Z"
    },
    "papermill": {
     "duration": 48.209054,
     "end_time": "2023-06-21T09:31:17.904235",
     "exception": false,
     "start_time": "2023-06-21T09:30:29.695181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 229MB/s]\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_S_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_v2_s-dd5fe13b.pth\n",
      "100%|██████████| 82.7M/82.7M [00:01<00:00, 66.3MB/s]\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
      "100%|██████████| 104M/104M [00:00<00:00, 234MB/s] \n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n",
      "100%|██████████| 49.7M/49.7M [00:00<00:00, 199MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - ResNet50 Training Loss: 1.1410\n",
      "Epoch 1/3 - EfficientNetV2 Training Loss: 1.0820\n",
      "Epoch 1/3 - Inception V3 Training Loss: 1.1715\n",
      "Epoch 1/3 - GoogLeNet Training Loss: 1.1122\n",
      "Epoch 1/3 - Validation Loss: 1.1064, Accuracy: 0.2667, F1 Score: 0.1906\n",
      "Best Ever Accuracy: 0.26666666666666666\n",
      "Epoch 2/3 - ResNet50 Training Loss: 1.0625\n",
      "Epoch 2/3 - EfficientNetV2 Training Loss: 1.0837\n",
      "Epoch 2/3 - Inception V3 Training Loss: 1.1341\n",
      "Epoch 2/3 - GoogLeNet Training Loss: 1.0987\n",
      "Epoch 2/3 - Validation Loss: 1.0511, Accuracy: 0.7333, F1 Score: 0.7133\n",
      "Best Ever Accuracy: 0.7333333333333333\n",
      "Epoch 3/3 - ResNet50 Training Loss: 0.9298\n",
      "Epoch 3/3 - EfficientNetV2 Training Loss: 1.0511\n",
      "Epoch 3/3 - Inception V3 Training Loss: 1.1163\n",
      "Epoch 3/3 - GoogLeNet Training Loss: 1.0534\n",
      "Epoch 3/3 - Validation Loss: 1.0391, Accuracy: 0.6000, F1 Score: 0.5371\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "# Load pre-trained models\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "efficientnet_model = models.efficientnet_v2_s(pretrained=True)\n",
    "inception_model = models.inception_v3(pretrained=True, aux_logits=True)\n",
    "googlenet_model = models.googlenet(pretrained=True)\n",
    "\n",
    "# Freeze all the parameters of the pretrained models\n",
    "for param in resnet_model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in efficientnet_model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in inception_model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in googlenet_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the last fully connected layers to match the number of classes\n",
    "num_classes = 3\n",
    "resnet_model.fc = nn.Linear(resnet_model.fc.in_features, num_classes)\n",
    "efficientnet_model.classifier[-1] = nn.Linear(efficientnet_model.classifier[-1].in_features, num_classes)\n",
    "inception_model.fc = nn.Linear(inception_model.fc.in_features, num_classes)\n",
    "googlenet_model.fc = nn.Linear(googlenet_model.fc.in_features, num_classes)\n",
    "\n",
    "# Move the models to the device (GPU if available)\n",
    "resnet_model = resnet_model.to(device)\n",
    "efficientnet_model = efficientnet_model.to(device)\n",
    "inception_model = inception_model.to(device)\n",
    "googlenet_model = googlenet_model.to(device)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizers for each model\n",
    "optimizer_resnet = optim.Adam(resnet_model.parameters(), lr=0.001)\n",
    "optimizer_efficientnet = optim.Adam(efficientnet_model.parameters(), lr=0.001)\n",
    "optimizer_inception = optim.Adam(inception_model.parameters(), lr=0.001)\n",
    "optimizer_googlenet = optim.Adam(googlenet_model.parameters(), lr=0.001)\n",
    "\n",
    "# Set the initial best validation loss and accuracy\n",
    "best_val_loss = float('inf')\n",
    "best_val_f1 = 0.0\n",
    "best_val_acc = 0.0\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase for ResNet50\n",
    "    resnet_model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer_resnet.zero_grad()\n",
    "        outputs = resnet_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_resnet.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - ResNet50 Training Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # Training phase for EfficientNetV2\n",
    "    efficientnet_model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer_efficientnet.zero_grad()\n",
    "        outputs = efficientnet_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_efficientnet.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - EfficientNetV2 Training Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # Training phase for Inception V3\n",
    "    inception_model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = inception_model(images)\n",
    "        logits = outputs.logits  # Get the output logits\n",
    "\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer_inception.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_inception.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Inception V3 Training Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # Training phase for GoogLeNet\n",
    "    googlenet_model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer_googlenet.zero_grad()\n",
    "        outputs = googlenet_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_googlenet.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - GoogLeNet Training Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # Validation phase\n",
    "    resnet_model.eval()\n",
    "    efficientnet_model.eval()\n",
    "    inception_model.eval()\n",
    "    googlenet_model.eval()\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_f1 = 0.0\n",
    "    val_accuracy = 0.0\n",
    "    total_predictions = torch.tensor([], dtype=torch.long, device=device)  # Initialize total_predictions\n",
    "    total_labels = torch.tensor([], dtype=torch.long, device=device)  # Initialize total_labels\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # ResNet50\n",
    "            resnet_outputs = resnet_model(images)\n",
    "            resnet_loss = criterion(resnet_outputs, labels)\n",
    "\n",
    "            # EfficientNetV2\n",
    "            efficientnet_outputs = efficientnet_model(images)\n",
    "            efficientnet_loss = criterion(efficientnet_outputs, labels)\n",
    "\n",
    "            # Inception V3\n",
    "            inception_outputs = inception_model(images)\n",
    "            inception_loss = criterion(inception_outputs, labels)\n",
    "\n",
    "            # GoogLeNet\n",
    "            googlenet_outputs = googlenet_model(images)\n",
    "            googlenet_loss = criterion(googlenet_outputs, labels)\n",
    "\n",
    "            # Combine losses\n",
    "            loss = (resnet_loss + efficientnet_loss + inception_loss + googlenet_loss) / 4.0\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predictions = torch.max((resnet_outputs + efficientnet_outputs + inception_outputs + googlenet_outputs) / 4.0, 1)\n",
    "            val_accuracy += torch.sum(predictions == labels).item()\n",
    "\n",
    "            # Calculate F1-score\n",
    "            predictions = (resnet_outputs + efficientnet_outputs + inception_outputs + googlenet_outputs) / 4.0\n",
    "            predictions = torch.argmax(predictions, dim=1)\n",
    "\n",
    "            total_predictions = torch.cat((total_predictions, predictions), dim=0)\n",
    "            total_labels = torch.cat((total_labels, labels), dim=0)\n",
    "\n",
    "    val_loss /= len(val_dataloader)\n",
    "    val_f1 = f1_score(total_labels.cpu(), total_predictions.cpu(), average='weighted')  # Calculate F1-score outside the loop\n",
    "    val_accuracy /= len(val_dataloader.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}, F1 Score: {val_f1:.4f}\")\n",
    "    # Checkpointing based on F1 score\n",
    "    if val_accuracy > best_val_acc :\n",
    "        best_val_acc  = val_accuracy\n",
    "        print(f\"Best Ever Accuracy: {best_val_acc}\")\n",
    "        torch.save(resnet_model.state_dict(), 'best_resnet_model.pth')\n",
    "        torch.save(efficientnet_model.state_dict(), 'best_efficientnet_model.pth')\n",
    "        torch.save(inception_model.state_dict(), 'best_inception_model.pth')\n",
    "        torch.save(googlenet_model.state_dict(), 'best_googlenet_model.pth')\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14387ce2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T09:31:17.922490Z",
     "iopub.status.busy": "2023-06-21T09:31:17.922181Z",
     "iopub.status.idle": "2023-06-21T09:31:33.007137Z",
     "shell.execute_reply": "2023-06-21T09:31:33.004637Z"
    },
    "papermill": {
     "duration": 15.096672,
     "end_time": "2023-06-21T09:31:33.009417",
     "exception": false,
     "start_time": "2023-06-21T09:31:17.912745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_dir, labeled_images, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.filenames = [file for file in os.listdir(image_dir) if file.endswith('.png') and file not in labeled_images]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.filenames[idx]\n",
    "        img_path = os.path.join(self.image_dir, file_name)\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, file_name\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set the directory paths\n",
    "image_dir = '/kaggle/working/padded_images'\n",
    "image_dir = '/kaggle/input/oxml-carinoma-classification'\n",
    "\n",
    "# Load labeled images from labels.csv\n",
    "labeled_images = labeled_data['id'].astype(str).values\n",
    "labeled_images ='img_' + labeled_images + '.png'\n",
    "# Define the main data transform\n",
    "main_transform = transforms.Compose([\n",
    "    transforms.Resize((max_height, max_width)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Create the main dataset\n",
    "dataset = CustomDataset(image_dir, labeled_images, transform=main_transform)\n",
    "\n",
    "# Create the data loader\n",
    "batch_size = 8\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Load the trained model weights\n",
    "resnet_model.load_state_dict(torch.load('best_resnet_model.pth'))\n",
    "efficientnet_model.load_state_dict(torch.load('best_efficientnet_model.pth'))\n",
    "inception_model.load_state_dict(torch.load('best_inception_model.pth'))\n",
    "googlenet_model.load_state_dict(torch.load('best_googlenet_model.pth'))\n",
    "\n",
    "# Testing phase\n",
    "resnet_model.eval()\n",
    "efficientnet_model.eval()\n",
    "inception_model.eval()\n",
    "googlenet_model.eval()\n",
    "\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, filenames in dataloader:\n",
    "        images = images.to(device)\n",
    "\n",
    "        # ResNet50\n",
    "        resnet_outputs = resnet_model(images)\n",
    "\n",
    "        # EfficientNetV2\n",
    "        efficientnet_outputs = efficientnet_model(images)\n",
    "\n",
    "        # Inception V3\n",
    "        inception_outputs = inception_model(images)\n",
    "\n",
    "        # GoogLeNet\n",
    "        googlenet_outputs = googlenet_model(images)\n",
    "\n",
    "        # Combine predictions\n",
    "        combined_outputs = (resnet_outputs + efficientnet_outputs + inception_outputs + googlenet_outputs) / 4.0\n",
    "\n",
    "        predicted_labels = torch.argmax(combined_outputs, dim=1)\n",
    "        predicted_labels = predicted_labels.cpu().detach().numpy() - 1\n",
    "\n",
    "        for filename, label in zip(filenames, predicted_labels):\n",
    "            predictions.append([filename, label])\n",
    "\n",
    "# Create a DataFrame for the predictions\n",
    "output = pd.DataFrame(predictions, columns=['id', 'malignant'])\n",
    "# Convert the 'id' column to integer type\n",
    "output['id'] = output['id'].str.replace('.png', '', regex=False).str.replace('img_', '', regex=False).astype(int)\n",
    "\n",
    "# Sort the output DataFrame by \"id\"\n",
    "output.sort_values(by=\"id\", inplace=True)\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "output.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84c59699",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T09:31:33.026688Z",
     "iopub.status.busy": "2023-06-21T09:31:33.026381Z",
     "iopub.status.idle": "2023-06-21T09:31:33.042830Z",
     "shell.execute_reply": "2023-06-21T09:31:33.041780Z"
    },
    "papermill": {
     "duration": 0.028084,
     "end_time": "2023-06-21T09:31:33.045458",
     "exception": false,
     "start_time": "2023-06-21T09:31:33.017374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>malignant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5042</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28148</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35946</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37944</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39157</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>959476</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>968389</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>976505</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>996288</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>997841</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  malignant\n",
       "0      5042         -1\n",
       "1     28148         -1\n",
       "2     35946          1\n",
       "3     37944          0\n",
       "4     39157         -1\n",
       "..      ...        ...\n",
       "119  959476         -1\n",
       "120  968389         -1\n",
       "121  976505          1\n",
       "122  996288         -1\n",
       "123  997841         -1\n",
       "\n",
       "[124 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1295089b",
   "metadata": {
    "papermill": {
     "duration": 0.007901,
     "end_time": "2023-06-21T09:31:33.061475",
     "exception": false,
     "start_time": "2023-06-21T09:31:33.053574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 150.940561,
   "end_time": "2023-06-21T09:31:36.129030",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-21T09:29:05.188469",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
